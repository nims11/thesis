% Parent problem, approaches, CAL and its history
\textit{High Recall Information Retrieval} is crucial for applications where the
goal is to find all or nearly all relevant documents using minimal human effort.
In information retrieval, \textit{recall} is defined as the fraction of relevant
documents retrieved, and \textit{precision} is defined as the fraction of
retrieved documents which were relevant. High recall retrieval systems are
designed to achieve high recall (finding all or nearly all relevant documents)
while maintaining a high precision (using minimal human effort on non-relevant
documents). This is in contrast to popular web-based search engines which are
optimized for early precision. Such retrieval systems are built to deliver a
small set of highly precise (but not necessarily high recall) results to its
users.

High recall retrieval systems are useful in tasks such as (but not limited to)
electronic discovery, systematic review, patent search and literature review. In
evidence based medicine, \textit{systematic review} is the process of summarizing all the evidence
pertaining to a research question. This often involves performing an exhaustive
literature review of relevant biomedical research and studies done in the past.
Finding all the relevant citations from a vast biomedical literature is a high
recall problem. \textit{eDiscovery} is another such high recall problem. In the
legal domain, \textit{eDiscovery} refers to the process followed by a party
which is required to find and present a (practically) complete set of documents
relevant to a particular matter.  Finding and reviewing documents from
potentially millions of documents can become very expensive in absence of
specialized retrieval systems. The requirements of
retrieval tasks in eDiscovery and systematic review share various
similarities~\cite{lease2016systematic,oard2013information}. Both
these tasks have traditionally relied on extensive manual review with limited computer
assistance. The search space these retrieval tasks operate on has been expanding
at a massive rate~\cite{bastian2010seventy,paul2006information}. As a result, systems
which help achieve high recall while reducing the work of human reviewers are
becoming more desirable.


Various approaches addressing the problem of high recall information retrieval
under various applications
exist~\cite{li2014req,hogan2010automation,cormack2014evaluation}. Technical
Assisted Review (TAR) is an umbrella term for computer assisted techniques used
to perform eDiscovery.  In a TAR method, a computer system works alongside
humans to classify documents as either relevant or non-relevant. TAR methods
usually incorporate some form of relevance feedback mechanism to gain a
better understanding of the search task. An effective TAR process would require
the human assessor to process a small fraction of the entire document set and
use that information to precisely predict the relevance of the remaining
documents. TAR methods have shown to outperform manual review in legal
eDiscovery by reducing the cost spent on human
assessors~\cite{grossman2010technology,roitblat2010document}.   Continuous
active learning (CAL)~\cite{cormack2014evaluation,cormack2015autonomy} is a TAR
protocol where a machine learning algorithm suggests most likely relevant
documents for human assessment and continuously incorporates relevance feedback
to improve its understanding of the search task.  In a previous study,
~\citet{cormack2014evaluation} showed that CAL outperforms other TAR
protocols on review tasks from actual legal matters and TREC 2009 Legal Track.
The Total Recall track in TREC 2015 and 2016 evaluated different systems under a
simulated TAR setting~\cite{grossman2016trec,roegiest2015trec}.  Baseline Model
Implementation (BMI) based on CAL was used as the baseline in these tracks. None
of the participating systems were able to consistently outperform the baseline.
BMI implements the AutoTAR (Autonomous TAR)
algorithm~\cite{cormack2015autonomy}, which enhances the autonomy of CAL by
requiring only a single seed relevant document or query to bootstrap the TAR
process.

In this thesis, we modify and extend the AutoTAR CAL algorithm. We isolate an
important step of the algorithm and call it \textit{refreshing}.  During a
\textit{refresh}, the relevance judgments from the assessor are used to train a
new classifier. This classifier generates an ordered list of documents most
likely to be relevant, which is later processed by the assessor. Apart from
being a crucial factor in the effectiveness of the retrieval algorithm, this
step also has a high computation cost because it involves training a classifier
and computing relevance likelihood scores for potentially all the documents in
the corpus. A \textit{refresh strategy} determines when and how to perform the
refresh. For example, in the AutoTAR algorithm, refreshing is done after a
certain number of documents are assessed. This number increases exponentially
over time. During a refresh, a classifier is trained using all the available
relevance judgments, and the entire document collection is scored to produce an
ordered set of most-likely-to-be-relevance documents for human assessment.

We propose various refresh strategies and compare their impact on the
effectiveness and efficiency of CAL. Following are the contributions we made
through the work described in this thesis:
\begin{itemize}
    \item Effectiveness of CAL (specifically, its ability to achieve higher
        recall with less effort) can be improved by performing more frequent
        refreshes. We found that refreshing after every assessment can
        consistently outperform other refresh strategies.

    \item Frequent refreshing can be computationally expensive for large
        datasets or low resource environment. We propose strategies which perform
        refresh on a smaller subset of data or use precision as a refresh
        criteria. These strategies achieve similar effectiveness as the most
        effective strategy (i.e., refreshing after every assessment), while being
        efficient with computation.

    \item We investigated prioritization of recently judged documents as a way to
        enhance the training of the classifier. While recency weighting didn't result in any
        improvements, it did help recover a fraction of the lost effectiveness
        when used with a weak but faster setting of the training algorithm.

    \item  The work described in this thesis required a suitable implementation
        of CAL.  We designed a modern and efficient
        implementation of CAL which can support aggressive refresh strategies.
        Our tool is open
        source~\footnote{\url{https://github.com/HiCAL/HiCAL/tree/master/CALEngine}}
        and designed to be used both as a research tool and in real world
        applications.  
\end{itemize}


\section{Thesis Organization}

The organization of the remainder of this thesis is described below.

In Chapter~\ref{chap:rel}, we introduce prerequisites to understanding the
subsequent chapters of this thesis. We discuss the Continuous Active Learning
algorithm and define the concept of \textit{refresh} and \textit{refresh
strategy}. We then review related work approaching similar problems and work
which can be potentially applied to the problem addressed in this thesis.

In Chapter~\ref{chap:implementation}, we describe the design and features of
the implementation using which all the experiments in this thesis were
performed.

In Chapter~\ref{chap:dataset}, we discuss the design of our experiments, along
with the dataset and evaluation metrics used.

In Chapter~\ref{chap:refresh}, we define and explain various refresh strategies.  In
Chapter~\ref{chap:results}, we evaluate and compare the performance of these
refresh strategies.

In Chapter~\ref{chap:conclusion}, we discuss the conclusions of our work
and the future work addressing various practical applications.
