\label{chap:conclusion}
% summarize everything
We investigated a crucial part of the Continuous Active Learning (CAL) process
called \textit{refreshing}. We proposed and compared various \textit{refresh
strategies}. Our results show that by refreshing more often, CAL can be used to
achieve higher recall. Refreshing after every judgment (\textit{static\_batch}($k
= 1$)) results in consistently better performance than the original BMI AutoTAR
in terms of recall. However, frequent refreshing is computationally more
expensive than the BMI refresh
strategy. But with an efficient implementation on modern computers, frequent
refreshing can be practically used in real world CAL systems.  We also defined and
analysed alternative refresh strategies which are as effective as refreshing
after every judgments. In our experiments, various settings of \textit{partial refresh
strategy} and \textit{precision strategy} achieved recall scores similar to
\textit{static\_batch($k = 1$)} at a lower computation cost. For situations
where computational resources are limited or dataset is very large,
\textit{partial refresh strategy} can be used. \textit{Precision based
refreshing} is efficient when the relevant documents are abundant and easier to
find.

We also provide an efficient C++ implementation of CAL and all the refresh
strategies mentioned in this paper as an open source tool. The tool is designed
to be used both as a research tool and in real world applications.

% static-1 if your corpus and resources are a match
% others parameters to tune to squeeze out performance

\section{Future Work}
There are a many large scale datasets (ClueWeb, Twitter, etc) which far exceed
the scale of dataset used in this paper.  It is desirable to run CAL efficiently on
these datasets. We described an enhancement to the \textit{partial refresh
strategy} which could potentially achieve this. Additional strategies which deal
with large amount of data could also be designed. In addition to
runtime efficiency, these strategies will also need to optimize for memory
efficiency.

In this paper, we measure computational efficiency of strategies using the
running time of the simulations. In a more practical setting where an actual
human is judging documents, responsiveness of the CAL system also becomes
important.  Under \textit{static batch refresh strategy}, we mentioned the idea
of introducing a \textit{delay} to improve responsiveness of CAL systems. Additional
experiments which simulate and measure the impact of those delays could be
designed.

